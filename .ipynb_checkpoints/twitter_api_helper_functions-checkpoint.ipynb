{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import os \n",
    "import datetime\n",
    "import tweepy\n",
    "import json \n",
    "import csv\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the twitter API keys and secrets form enviroment variables \n",
    "# These are used to make calls to all the Twitter apis used bellow\n",
    "\n",
    "consumer_key = os.getenv(\"TWITTER_CONSUMER_KEY\")\n",
    "consumer_secret = os.getenv(\"TWITTER_CONSUMER_SECRET\")\n",
    "access_key = os.getenv(\"TWITTER_ACCESS_KEY\")\n",
    "access_secret = os.getenv(\"TWITTER_ACCESS_SECRET\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeline(screen_name, state_name):\n",
    "    \n",
    "    # Authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, \n",
    "                     wait_on_rate_limit_notify=True)\n",
    "\n",
    "    # Assign metadata fields\n",
    "    Data = namedtuple(\"Data\", [\"handle\", \"handle_id\", \"date_scraped\", \n",
    "                               \"latest_tweet_id\", \"total_tweets\", \n",
    "                               \"tweets_per_week\", \"account_created_date\", \n",
    "                               \"account_status\"])\n",
    "    \n",
    "    alltweets = []  # Will store all the scraped tweets \n",
    "    \n",
    "    try:\n",
    "        # Make initial call\n",
    "        user = api.get_user(screen_name)\n",
    "        \n",
    "        # Check if the account is protected\n",
    "        if user.protected == True:  \n",
    "            print('protected')\n",
    "            metadata = Data(screen_name, 'NA', 'NA', 'NA', 'NA', 'NA', 'NA',\n",
    "                            'protected')  \n",
    "\n",
    "        # If not, make initial request\n",
    "        else:\n",
    "\n",
    "            print('not protected')\n",
    "            new_tweets = api.user_timeline(screen_name=screen_name, \n",
    "                                           count=200, \n",
    "                                           exclude_replies=False, \n",
    "                                           tweet_mode=\"extended\")    \n",
    "\n",
    "            # Check if the account posted any tweets \n",
    "            if len(new_tweets)==0:\n",
    "                print('zero tweets')\n",
    "                metadata = Data(screen_name, 'NA', 'NA', 'NA', 'NA', 'NA', 'NA',\n",
    "                                'no tweets')\n",
    "       \n",
    "            # Check if the account has been active in the last year\n",
    "            else:    \n",
    "                time_delta = datetime.date.today() - new_tweets[0].created_at.date()\n",
    "                if time_delta.days > 365:\n",
    "                    print('account inactive')\n",
    "                    metadata = Data(screen_name, 'NA', 'NA', 'NA', 'NA', 'NA',\n",
    "                                    'NA', 'inactive')   \n",
    "                    \n",
    "                else:\n",
    "                    # If the account is active add tweets to alltweets \n",
    "                    alltweets.extend(new_tweets)\n",
    "                    \n",
    "                    # Save the id of the oldest tweet less one\n",
    "                    oldest = alltweets[-1].id - 1\n",
    "                    \n",
    "                    # Keep grabbing tweets until there are no tweets left to grab\n",
    "                    while len(new_tweets) > 0:\n",
    "                        print (\"getting tweets before %s\" % (oldest))\n",
    "                        \n",
    "                        new_tweets = api.user_timeline(\n",
    "                            screen_name = screen_name, \n",
    "                            count=200, max_id=oldest, \n",
    "                            exclude_replies=False,                       \n",
    "                            tweet_mode=\"extended\")\n",
    "\n",
    "                        alltweets.extend(new_tweets)\n",
    "\n",
    "                        # Update the id of the oldest tweet less one\n",
    "                        oldest = alltweets[-1].id - 1\n",
    "                        print (\"...%s tweets downloaded so far\" % \n",
    "                               (len(alltweets)))\n",
    "                        \n",
    "                    # Check how many tweets were posted in the last 7 days\n",
    "                    eight_days_ago = datetime.date.today() - datetime.timedelta(days = 8)\n",
    "                    counter = 0\n",
    "                    for tweet in alltweets:\n",
    "                        if tweet.created_at.date() < eight_days_ago:\n",
    "                            break\n",
    "                        else:\n",
    "                            counter+=1\n",
    "                            \n",
    "                    # Collect metedata fields \n",
    "                    date_scraped = datetime.date.today()          \n",
    "                    account_id = alltweets[0].user.id\n",
    "                    latest_tweet_id = alltweets[0].id\n",
    "                    total_tweets = len(alltweets)\n",
    "                    last_week_total_tweets = counter\n",
    "                    active_since = alltweets[0].user.created_at.date()\n",
    "                    \n",
    "                    metadata = Data(screen_name, account_id, date_scraped, \n",
    "                                    latest_tweet_id, total_tweets, \n",
    "                                    last_week_total_tweets, active_since, \n",
    "                                    'active')\n",
    "                    \n",
    "    # Except exception if the user does not exist or is suspended \n",
    "    except tweepy.error.TweepError as e:\n",
    "        if (e.api_code == 50) or (e.api_code == 63):\n",
    "            print(e)\n",
    "            metadata = Data(screen_name, 'NA', 'NA', 'NA', 'NA', 'NA', 'NA', \n",
    "                            e.args[0][0]['message'])\n",
    "            \n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Return results         \n",
    "    if len(alltweets)>0:\n",
    "        results_dic = {'tweets': alltweets, 'metadata': metadata}\n",
    "    else:\n",
    "        results_dic = {'tweets':'NA', 'metadata' : metadata}\n",
    "        \n",
    "    return results_dic               \n",
    "                               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue timeline collection \n",
    "\n",
    "def get_timeline_since(screen_name, since_id):\n",
    "    \n",
    "    \n",
    "# Authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True,\n",
    "                    wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    date_scraped = datetime.date.today()          \n",
    "    \n",
    "    # Create a tupple to collect metadata\n",
    "    Data = namedtuple(\"Data\", [\"handle\", \"date_scraped\", \n",
    "                           \"latest_tweet_id\", \"total_tweets\", \"active\"])\n",
    "\n",
    "    # Initialize empty list to store tweets\n",
    "    alltweets =[]\n",
    "    \n",
    "    try: \n",
    "        \n",
    "        # Make initial call\n",
    "        user = api.get_user(screen_name)\n",
    "        \n",
    "        # Check if the account is protected\n",
    "        if user.protected == True:  \n",
    "            print('protected')\n",
    "            \n",
    "            # Store results\n",
    "            metadata = Data(screen_name, date_scraped, since_id,\n",
    "                            'NA', 'protected')\n",
    "            \n",
    "            results_dic = {'tweets': alltweets, \n",
    "                           'metadata' : metadata}\n",
    "                            \n",
    "        # If not protected, make a call to collect all tweets \n",
    "        else: \n",
    "            for tweet in tweepy.Cursor(api.user_timeline, \n",
    "                                       screen_name= screen_name, \n",
    "                                       since_id = since_id, \n",
    "                                       count=200, \n",
    "                                       exclude_replies=False, \n",
    "                                       tweet_mode=\"extended\").items():\n",
    "\n",
    "                    alltweets.append(tweet)\n",
    "\n",
    "            print(len(alltweets))\n",
    "            \n",
    "            # Check if there are non 0 tweets\n",
    "            if len(alltweets) > 0:\n",
    "                \n",
    "                # Store results\n",
    "                latest_tweet_id = alltweets[0].id\n",
    "                total_tweets = len(alltweets)\n",
    "                \n",
    "                metadata = Data(screen_name, date_scraped, latest_tweet_id, \n",
    "                                total_tweets, 'active')\n",
    "                \n",
    "                results_dic = {'tweets':alltweets, \n",
    "                               'metadata' : metadata}\n",
    "\n",
    "            else: \n",
    "                # Store results\n",
    "                metadata = Data(screen_name, \n",
    "                                date_scraped, \n",
    "                                since_id, \n",
    "                                0,\n",
    "                                'active')\n",
    "\n",
    "                results_dic = {'tweets':alltweets, \n",
    "                               'metadata' : metadata}\n",
    "            \n",
    "    # Except Exception if: \n",
    "    # 1. the user does not exist \n",
    "    # 2. the user is suspended  \n",
    "    # 3. the page does not exist\n",
    "    \n",
    "    except tweepy.error.TweepError as e:\n",
    "        if (e.api_code == 50) or (e.api_code == 63) or ('404' in e.reason):\n",
    "            print(e)\n",
    "            \n",
    "            # Store results \n",
    "            metadata = Data(screen_name, date_scraped, since_id, \n",
    "                            'NA', e)\n",
    "            \n",
    "            results_dic = {'tweets':alltweets, \n",
    "                           'metadata' : metadata}\n",
    "            \n",
    "        # Raise unexpected exceptions    \n",
    "        else:\n",
    "            raise\n",
    "        \n",
    "    # Return results -- the tweets and metadata are stored in a dictionary\n",
    "    return results_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for collecting the the ids of accounts that follow our target account \n",
    "# Makes use of Twitter's followers_ids api and grabs 5000 followes in every request\n",
    "# 15 requests/15 minutes are allowed \n",
    "\n",
    "# Assumes your are in the main directory (the state folder) where subfolders of each account are present\n",
    "# Example: Set the directory to 'California' to collect followers of legislators from California \n",
    "\n",
    "\n",
    "def get_follower_ids(screen_name):    \n",
    "\n",
    "    # Authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, \n",
    "                     wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        followerids =[]\n",
    "        \n",
    "        for user in tweepy.Cursor(api.followers_ids, screen_name= screen_name ,count=5000).items():\n",
    "            followerids.append(user)\n",
    "          \n",
    "        # Create file name \n",
    "        date_scraped = datetime.date.today().strftime('%B%d')\n",
    "        follower_len = len(followerids)\n",
    "        file_name = '%s/%s_FollowerIds_%s_%s.csv' %(screen_name, screen_name, date_scraped, follower_len)\n",
    "        \n",
    "        # Write to file\n",
    "        pd.Series(followerids).to_csv(file_name, index = False, header = False)\n",
    "           \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for collecting the the ids of accounts that are followed by our target account \n",
    "# Makes use of Twitter's friends_ids api and grabs 5000 followes in every request\n",
    "# 15 requests/15 minutes are allowed \n",
    "\n",
    "# Assumes your are in the main directory (the state folder) where subfolders of each account are present\n",
    "# Example: Set the directory to 'California' to collect friends of legislators from California \n",
    "\n",
    "def get_friend_ids(screen_name):\n",
    "\n",
    "    # Authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    try:\n",
    "        friendsids =[]\n",
    "        \n",
    "        for user in tweepy.Cursor(api.friends_ids, screen_name= screen_name,count=5000).items():\n",
    "            friendsids.append(user)\n",
    "        \n",
    "        # Create file name\n",
    "        date_scraped = datetime.date.today().strftime('%B%d')\n",
    "        friends_len = len(friendsids)\n",
    "        file_name = '%s/%s_FriendsIds_%s_%s.csv' %(screen_name, screen_name, date_scraped, friends_len)\n",
    "        \n",
    "        # Write to file\n",
    "        pd.Series(friendsids).to_csv(file_name, index = False, header = False)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State names and their abbreviations \n",
    "\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create metadat file \n",
    "\n",
    "# def create_metadata(StateName, metadata_num, col, handles):\n",
    "    \n",
    "#         df = pd.DataFrame(columns= cols,  \n",
    "#                             index= handles)  # create it \n",
    "\n",
    "#         today = datetime.date.today().strftime(\"%B%d\") \n",
    "#         fname = '%s_' % state_name + metadata_num + '.csv'\n",
    "#         df.to_csv(fname)  \n",
    "\n",
    "#         status = 'Created file named: %s'%fname)\n",
    "        \n",
    "        \n",
    "#     else: \n",
    "#         print('File already exists: %s' %path[0]) \n",
    "#         return path[0]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
